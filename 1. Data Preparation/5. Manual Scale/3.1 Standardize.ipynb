{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.1 Standardize.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### 손으로 쓴 숫자 이미지 데이터"
      ],
      "metadata": {
        "id": "vofV73ermUzn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-tOktq1mMYb",
        "outputId": "0446fd9f-3a73-4943-da69-250a7554d23d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Train (60000, 28, 28) (60000,)\n",
            "Test ((10000, 28, 28), (10000,))\n",
            "Statistics train=33.318 (78.567), test=33.791 (79.172)\n",
            "Data Generator mean=33.318, std=78.567\n",
            "Batch shape=(60000, 28, 28, 1), mean=-0.000, std=1.000\n",
            "Batches train=938, test=157\n",
            "Batch shape=(64, 28, 28, 1), mean=-0.016, std=0.979\n",
            "Epoch 1/5\n",
            "938/938 [==============================] - 58s 60ms/step - loss: 0.1412 - accuracy: 0.9571\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 55s 59ms/step - loss: 0.0479 - accuracy: 0.9853\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 54s 57ms/step - loss: 0.0336 - accuracy: 0.9892\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 53s 56ms/step - loss: 0.0246 - accuracy: 0.9923\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 53s 57ms/step - loss: 0.0187 - accuracy: 0.9941\n",
            "Test Accuracy: 98.810\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 데이터 세트 로드\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\n",
        "# 데이터 세트 크기\n",
        "print('Train', trainX.shape, trainY.shape)\n",
        "print('Test', (testX.shape, testY.shape))\n",
        "# 이미지 정보 확인\n",
        "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' % (trainX.mean(), trainX.std(), testX.mean(), testX.std()))\n",
        "\n",
        "# 데이터 세트 형태 변경\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "\n",
        "# 원 핫 인코딩\n",
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY)\n",
        "\n",
        "# \b표준화\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "datagen.fit(trainX)\n",
        "print('Data Generator mean=%.3f, std=%.3f' % (datagen.mean, datagen.std))\n",
        "\n",
        "# 이미지 전체에 대한 중앙값 확인\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=len(trainX), shuffle=False)\n",
        "batchX, batchy = iterator.next()\n",
        "print('Batch shape=%s, mean=%.3f, std=%.3f' % (batchX.shape, batchX.mean(), batchX.std()))\n",
        "\n",
        "# 배치 사이즈 설정\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
        "# 배치 정보 확인\n",
        "batchX, batchy = train_iterator.next()\n",
        "print('Batch shape=%s, mean=%.3f, std=%.3f' % (batchX.shape, batchX.mean(), batchX.std()))\n",
        "\n",
        "# 모델 정의\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# 모델 컴파일\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# 모델 생성\n",
        "model.fit(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\n",
        "# 모델 평가\n",
        "_, acc = model.evaluate(test_iterator, steps=len(test_iterator), verbose=0)\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ]
    }
  ]
}