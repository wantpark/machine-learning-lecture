{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "block_hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "import logging\n",
    "logging.getLogger('prophet').setLevel(logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "block_hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial log joint probability = 7.93852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<prophet.forecaster.Prophet at 0x10f1edbb0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  1. Log joint probability =      57.08. Improved by 49.1415.\n",
      "Iteration  2. Log joint probability =    78.9415. Improved by 21.8615.\n",
      "Iteration  3. Log joint probability =     86.796. Improved by 7.85447.\n",
      "Iteration  4. Log joint probability =    102.536. Improved by 15.7401.\n",
      "Iteration  5. Log joint probability =     114.79. Improved by 12.2542.\n",
      "Iteration  6. Log joint probability =     145.87. Improved by 31.0799.\n",
      "Iteration  7. Log joint probability =     154.78. Improved by 8.9103.\n",
      "Iteration  8. Log joint probability =    169.043. Improved by 14.2626.\n",
      "Iteration  9. Log joint probability =    171.914. Improved by 2.87052.\n",
      "Iteration 10. Log joint probability =    193.801. Improved by 21.8879.\n",
      "Iteration 11. Log joint probability =    206.581. Improved by 12.7795.\n",
      "Iteration 12. Log joint probability =    219.356. Improved by 12.7748.\n",
      "Iteration 13. Log joint probability =    234.164. Improved by 14.8085.\n",
      "Iteration 14. Log joint probability =    247.001. Improved by 12.8372.\n",
      "Iteration 15. Log joint probability =    259.891. Improved by 12.8895.\n",
      "Iteration 16. Log joint probability =    267.991. Improved by 8.09978.\n",
      "Iteration 17. Log joint probability =    285.515. Improved by 17.524.\n",
      "Iteration 18. Log joint probability =    298.031. Improved by 12.5162.\n",
      "Iteration 19. Log joint probability =    316.386. Improved by 18.3552.\n",
      "Iteration 20. Log joint probability =    328.552. Improved by 12.1654.\n",
      "Iteration 21. Log joint probability =    385.143. Improved by 56.5918.\n",
      "Iteration 22. Log joint probability =    397.334. Improved by 12.1906.\n",
      "Iteration 23. Log joint probability =    442.093. Improved by 44.7592.\n",
      "Iteration 24. Log joint probability =    462.339. Improved by 20.2463.\n",
      "Iteration 25. Log joint probability =    475.232. Improved by 12.8925.\n",
      "Iteration 26. Log joint probability =    484.202. Improved by 8.96966.\n",
      "Iteration 27. Log joint probability =    500.121. Improved by 15.9191.\n",
      "Iteration 28. Log joint probability =    512.377. Improved by 12.2568.\n",
      "Iteration 29. Log joint probability =    539.682. Improved by 27.3049.\n",
      "Iteration 30. Log joint probability =    550.979. Improved by 11.2962.\n",
      "Iteration 31. Log joint probability =    560.191. Improved by 9.21198.\n",
      "Iteration 32. Log joint probability =    574.052. Improved by 13.8616.\n",
      "Iteration 33. Log joint probability =    578.119. Improved by 4.06714.\n",
      "Iteration 34. Log joint probability =    598.573. Improved by 20.4538.\n",
      "Iteration 35. Log joint probability =    611.466. Improved by 12.893.\n",
      "Iteration 36. Log joint probability =    622.871. Improved by 11.4052.\n",
      "Iteration 37. Log joint probability =    630.294. Improved by 7.42241.\n",
      "Iteration 38. Log joint probability =    646.389. Improved by 16.0953.\n",
      "Iteration 39. Log joint probability =    657.851. Improved by 11.4623.\n",
      "Iteration 40. Log joint probability =    666.183. Improved by 8.33171.\n",
      "Iteration 41. Log joint probability =    671.059. Improved by 4.87589.\n",
      "Iteration 42. Log joint probability =    673.101. Improved by 2.04166.\n",
      "Iteration 43. Log joint probability =    676.454. Improved by 3.35361.\n",
      "Iteration 44. Log joint probability =    678.093. Improved by 1.63867.\n",
      "Iteration 45. Log joint probability =    682.423. Improved by 4.33026.\n",
      "Iteration 46. Log joint probability =    686.605. Improved by 4.18213.\n",
      "Iteration 47. Log joint probability =    687.401. Improved by 0.79598.\n",
      "Iteration 48. Log joint probability =    688.897. Improved by 1.49625.\n",
      "Iteration 49. Log joint probability =    691.586. Improved by 2.68894.\n",
      "Iteration 50. Log joint probability =     691.83. Improved by 0.243279.\n",
      "Iteration 51. Log joint probability =    691.973. Improved by 0.143503.\n",
      "Iteration 52. Log joint probability =    692.419. Improved by 0.445365.\n",
      "Iteration 53. Log joint probability =    692.616. Improved by 0.197257.\n",
      "Iteration 54. Log joint probability =    692.981. Improved by 0.36479.\n",
      "Iteration 55. Log joint probability =    693.844. Improved by 0.863205.\n",
      "Iteration 56. Log joint probability =    695.799. Improved by 1.9549.\n",
      "Iteration 57. Log joint probability =    696.417. Improved by 0.617983.\n",
      "Iteration 58. Log joint probability =    699.236. Improved by 2.81919.\n",
      "Iteration 59. Log joint probability =     699.33. Improved by 0.0940594.\n",
      "Iteration 60. Log joint probability =    700.034. Improved by 0.704249.\n",
      "Iteration 61. Log joint probability =     700.34. Improved by 0.305545.\n",
      "Iteration 62. Log joint probability =    700.466. Improved by 0.126068.\n",
      "Iteration 63. Log joint probability =    700.896. Improved by 0.430647.\n",
      "Iteration 64. Log joint probability =    701.315. Improved by 0.418595.\n",
      "Iteration 65. Log joint probability =    701.477. Improved by 0.162056.\n",
      "Iteration 66. Log joint probability =    701.501. Improved by 0.0244008.\n",
      "Iteration 67. Log joint probability =    701.676. Improved by 0.174235.\n",
      "Iteration 68. Log joint probability =    702.029. Improved by 0.353219.\n",
      "Iteration 69. Log joint probability =    702.616. Improved by 0.586701.\n",
      "Iteration 70. Log joint probability =    703.273. Improved by 0.657295.\n",
      "Iteration 71. Log joint probability =    703.798. Improved by 0.525135.\n",
      "Iteration 72. Log joint probability =    703.821. Improved by 0.0231133.\n",
      "Iteration 73. Log joint probability =    703.957. Improved by 0.135864.\n",
      "Iteration 74. Log joint probability =    704.054. Improved by 0.0974218.\n",
      "Iteration 75. Log joint probability =    704.203. Improved by 0.149031.\n",
      "Iteration 76. Log joint probability =    704.652. Improved by 0.448273.\n",
      "Iteration 77. Log joint probability =    704.946. Improved by 0.294599.\n",
      "Iteration 78. Log joint probability =    705.539. Improved by 0.592894.\n",
      "Iteration 79. Log joint probability =    706.186. Improved by 0.647104.\n",
      "Iteration 80. Log joint probability =    706.684. Improved by 0.497513.\n",
      "Iteration 81. Log joint probability =    707.031. Improved by 0.346785.\n",
      "Iteration 82. Log joint probability =    707.681. Improved by 0.649988.\n",
      "Iteration 83. Log joint probability =    707.739. Improved by 0.058745.\n",
      "Iteration 84. Log joint probability =    707.777. Improved by 0.0376336.\n",
      "Iteration 85. Log joint probability =    707.847. Improved by 0.0701314.\n",
      "Iteration 86. Log joint probability =    707.888. Improved by 0.0409844.\n",
      "Iteration 87. Log joint probability =    707.927. Improved by 0.0384496.\n",
      "Iteration 88. Log joint probability =    708.246. Improved by 0.319433.\n",
      "Iteration 89. Log joint probability =    708.635. Improved by 0.388633.\n",
      "Iteration 90. Log joint probability =    708.639. Improved by 0.00421865.\n",
      "Iteration 91. Log joint probability =    708.662. Improved by 0.0226833.\n",
      "Iteration 92. Log joint probability =    708.752. Improved by 0.090794.\n",
      "Iteration 93. Log joint probability =    708.891. Improved by 0.139022.\n",
      "Iteration 94. Log joint probability =      708.9. Improved by 0.00888147.\n",
      "Iteration 95. Log joint probability =    708.996. Improved by 0.095728.\n",
      "Iteration 96. Log joint probability =    709.058. Improved by 0.0624447.\n",
      "Iteration 97. Log joint probability =    709.202. Improved by 0.143714.\n",
      "Iteration 98. Log joint probability =    709.246. Improved by 0.0439622.\n",
      "Iteration 99. Log joint probability =     709.46. Improved by 0.213771.\n",
      "Iteration 100. Log joint probability =    709.793. Improved by 0.332826.\n",
      "Iteration 101. Log joint probability =    709.825. Improved by 0.0321553.\n",
      "Iteration 102. Log joint probability =    709.954. Improved by 0.129642.\n",
      "Iteration 103. Log joint probability =    710.033. Improved by 0.0780191.\n",
      "Iteration 104. Log joint probability =    710.357. Improved by 0.324255.\n",
      "Iteration 105. Log joint probability =     710.41. Improved by 0.0531846.\n",
      "Iteration 106. Log joint probability =    710.574. Improved by 0.164354.\n",
      "Iteration 107. Log joint probability =    710.643. Improved by 0.0685908.\n",
      "Iteration 108. Log joint probability =    710.745. Improved by 0.102166.\n",
      "Iteration 109. Log joint probability =    710.761. Improved by 0.0159077.\n",
      "Iteration 110. Log joint probability =    710.866. Improved by 0.104573.\n",
      "Iteration 111. Log joint probability =    710.887. Improved by 0.0216383.\n",
      "Iteration 112. Log joint probability =    711.014. Improved by 0.127188.\n",
      "Iteration 113. Log joint probability =    711.065. Improved by 0.0507112.\n",
      "Iteration 114. Log joint probability =    711.065. Improved by 0.000110384.\n",
      "Iteration 115. Log joint probability =    711.065. Improved by 5.77157e-05.\n",
      "Iteration 116. Log joint probability =    711.084. Improved by 0.019089.\n",
      "Iteration 117. Log joint probability =      711.1. Improved by 0.0157717.\n",
      "Iteration 118. Log joint probability =     711.22. Improved by 0.119493.\n",
      "Iteration 119. Log joint probability =    711.459. Improved by 0.23984.\n",
      "Iteration 120. Log joint probability =     711.59. Improved by 0.130593.\n",
      "Iteration 121. Log joint probability =    711.772. Improved by 0.1822.\n",
      "Iteration 122. Log joint probability =    711.995. Improved by 0.222687.\n",
      "Iteration 123. Log joint probability =    712.004. Improved by 0.00882548.\n",
      "Iteration 124. Log joint probability =    712.095. Improved by 0.0914487.\n",
      "Iteration 125. Log joint probability =    712.272. Improved by 0.176607.\n",
      "Iteration 126. Log joint probability =    712.469. Improved by 0.19755.\n",
      "Iteration 127. Log joint probability =    712.487. Improved by 0.0174485.\n",
      "Iteration 128. Log joint probability =    712.535. Improved by 0.0479287.\n",
      "Iteration 129. Log joint probability =    712.847. Improved by 0.311843.\n",
      "Iteration 130. Log joint probability =    712.859. Improved by 0.0128746.\n",
      "Iteration 131. Log joint probability =    712.887. Improved by 0.0276438.\n",
      "Iteration 132. Log joint probability =    712.952. Improved by 0.0651744.\n",
      "Iteration 133. Log joint probability =    713.038. Improved by 0.0860403.\n",
      "Iteration 134. Log joint probability =    713.106. Improved by 0.0673554.\n",
      "Iteration 135. Log joint probability =    713.123. Improved by 0.0170762.\n",
      "Iteration 136. Log joint probability =    713.332. Improved by 0.209268.\n",
      "Iteration 137. Log joint probability =    713.375. Improved by 0.043367.\n",
      "Iteration 138. Log joint probability =    713.398. Improved by 0.0227499.\n",
      "Iteration 139. Log joint probability =    713.428. Improved by 0.0301587.\n",
      "Iteration 140. Log joint probability =    713.429. Improved by 0.000734862.\n",
      "Iteration 141. Log joint probability =    713.478. Improved by 0.0491113.\n",
      "Iteration 142. Log joint probability =    713.562. Improved by 0.0837288.\n",
      "Iteration 143. Log joint probability =    713.629. Improved by 0.0667036.\n",
      "Iteration 144. Log joint probability =    713.633. Improved by 0.00464366.\n",
      "Iteration 145. Log joint probability =    713.633. Improved by 5.63937e-05.\n",
      "Iteration 146. Log joint probability =    713.633. Improved by 2.92682e-05.\n",
      "Iteration 147. Log joint probability =    713.633. Improved by 7.3029e-06.\n",
      "Iteration 148. Log joint probability =    713.633. Improved by 1.82174e-06.\n",
      "Iteration 149. Log joint probability =    713.633. Improved by 2.28724e-07.\n",
      "Iteration 150. Log joint probability =    713.633. Improved by 1.14514e-07.\n",
      "Iteration 151. Log joint probability =    713.633. Improved by 2.85449e-08.\n",
      "Iteration 152. Log joint probability =    713.633. Improved by 1.42634e-08.\n",
      "Iteration 153. Log joint probability =    713.633. Improved by 7.1293e-09.\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'ds': pd.date_range(start='2020-01-01', periods=20),\n",
    "    'y': np.arange(20),\n",
    "})\n",
    "m = Prophet(weekly_seasonality=False)\n",
    "m.fit(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving models\n",
    "\n",
    "It is possible to save fitted Prophet models so that they can be loaded and used later.\n",
    "\n",
    "In R, this is done with `saveRDS` and `readRDS`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, models should not be saved with pickle; the Stan backend attached to the model object will not pickle well, and will produce issues under certain versions of Python. Instead, you should use the built-in serialization functions to serialize the model to json:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from prophet.serialize import model_to_json, model_from_json\n",
    "\n",
    "with open('serialized_model.json', 'w') as fout:\n",
    "    json.dump(model_to_json(m), fout)  # Save model\n",
    "\n",
    "with open('serialized_model.json', 'r') as fin:\n",
    "    m = model_from_json(json.load(fin))  # Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The json file will be portable across systems, and deserialization is backwards compatible with older versions of prophet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat trend and custom trends\n",
    "\n",
    "For time series that exhibit strong seasonality patterns rather than trend changes, it may be useful to force the trend growth rate to be flat. This can be achieved simply by passing `growth=flat` when creating the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet(growth='flat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that if this is used on a time series that doesn't have a constant trend, any trend will be fit with the noise term and so there will be high predictive uncertainty in the forecast.\n",
    "\n",
    "To use a trend besides these three built-in trend functions (piecewise linear, piecewise logistic growth, and flat), you can download the source code from github, modify the trend function as desired in a local branch, and then install that local version. [This PR](https://github.com/facebook/prophet/pull/1466/files) provides a good illustration of what must be done to implement a custom trend, as does [this one](https://github.com/facebook/prophet/pull/1794) that implements a step function trend and [this one](https://github.com/facebook/prophet/pull/1778) for a new trend in R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating fitted models\n",
    "\n",
    "A common setting for forecasting is fitting models that need to be updated as additional data come in. Prophet models can only be fit once, and a new model must be re-fit when new data become available. In most settings, model fitting is fast enough that there isn't any issue with re-fitting from scratch. However, it is possible to speed things up a little by warm-starting the fit from the model parameters of the earlier model. This code example shows how this can be done in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial log joint probability = -37.8933\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       7970.71     0.0207558       359.682           1           1      131   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       7985.55     0.0113783       318.816           1           1      251   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     299       7990.61   0.000367563       159.325      0.2964      0.2964      375   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399       7993.46    0.00190504       794.983           1           1      497   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     469       7995.12   9.79732e-05       288.502   2.216e-07       0.001      620  LS failed, Hessian reset \n",
      "     499       7996.27   0.000874007         225.9      0.2211       0.883      659   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     541       7996.64   6.35584e-05        164.34   5.274e-07       0.001      740  LS failed, Hessian reset \n",
      "     599       7997.13    0.00134586       95.3073      0.2989      0.9783      814   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     699       7997.46   0.000258983       90.7023           1           1      928   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     704       7997.49    6.6214e-05       192.547   5.911e-07       0.001      975  LS failed, Hessian reset \n",
      "     738       7997.52   3.72573e-07       61.9172      0.0515      0.8459     1018   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -19.4685\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       7975.31    0.00415855       247.015      0.7831      0.7831      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       7994.53      0.010249        344.02           1           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     223       7995.33   5.91718e-05       165.006   4.517e-07       0.001      316  LS failed, Hessian reset \n",
      "     299       7997.26   0.000813407       209.659       6.754      0.6754      400   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        8001.1   0.000792021       147.659      0.5991           1      526   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     488       8002.21   7.22552e-05       102.114   1.519e-07       0.001      675  LS failed, Hessian reset \n",
      "     499       8002.91   0.000721449       137.606           1           1      690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       8003.64     0.0047848       521.672           1           1      814   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     628       8004.26   5.71296e-05       153.514   1.864e-07       0.001      890  LS failed, Hessian reset \n",
      "     699       8004.62    0.00078023       134.695           1           1      976   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     753       8004.75   5.63457e-07        75.462           1           1     1045   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -19.4685\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       7975.31    0.00415855       247.015      0.7831      0.7831      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       7994.53      0.010249        344.02           1           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     223       7995.33   5.91718e-05       165.006   4.517e-07       0.001      316  LS failed, Hessian reset \n",
      "     299       7997.26   0.000813407       209.659       6.754      0.6754      400   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        8001.1   0.000792021       147.659      0.5991           1      526   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     488       8002.21   7.22552e-05       102.114   1.519e-07       0.001      675  LS failed, Hessian reset \n",
      "     499       8002.91   0.000721449       137.606           1           1      690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       8003.64     0.0047848       521.672           1           1      814   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     628       8004.26   5.71296e-05       153.514   1.864e-07       0.001      890  LS failed, Hessian reset \n",
      "     699       8004.62    0.00078023       134.695           1           1      976   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     753       8004.75   5.63457e-07        75.462           1           1     1045   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -19.4685\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       7975.31    0.00415855       247.015      0.7831      0.7831      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       7994.53      0.010249        344.02           1           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     223       7995.33   5.91718e-05       165.006   4.517e-07       0.001      316  LS failed, Hessian reset \n",
      "     299       7997.26   0.000813407       209.659       6.754      0.6754      400   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        8001.1   0.000792021       147.659      0.5991           1      526   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     488       8002.21   7.22552e-05       102.114   1.519e-07       0.001      675  LS failed, Hessian reset \n",
      "     499       8002.91   0.000721449       137.606           1           1      690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       8003.64     0.0047848       521.672           1           1      814   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     628       8004.26   5.71296e-05       153.514   1.864e-07       0.001      890  LS failed, Hessian reset \n",
      "     699       8004.62    0.00078023       134.695           1           1      976   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     753       8004.75   5.63457e-07        75.462           1           1     1045   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -19.4685\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       7975.31    0.00415855       247.015      0.7831      0.7831      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       7994.53      0.010249        344.02           1           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     223       7995.33   5.91718e-05       165.006   4.517e-07       0.001      316  LS failed, Hessian reset \n",
      "     299       7997.26   0.000813407       209.659       6.754      0.6754      400   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        8001.1   0.000792021       147.659      0.5991           1      526   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     488       8002.21   7.22552e-05       102.114   1.519e-07       0.001      675  LS failed, Hessian reset \n",
      "     499       8002.91   0.000721449       137.606           1           1      690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       8003.64     0.0047848       521.672           1           1      814   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     628       8004.26   5.71296e-05       153.514   1.864e-07       0.001      890  LS failed, Hessian reset \n",
      "     699       8004.62    0.00078023       134.695           1           1      976   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     753       8004.75   5.63457e-07        75.462           1           1     1045   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -19.4685\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       7975.31    0.00415855       247.015      0.7831      0.7831      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       7994.53      0.010249        344.02           1           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     223       7995.33   5.91718e-05       165.006   4.517e-07       0.001      316  LS failed, Hessian reset \n",
      "     299       7997.26   0.000813407       209.659       6.754      0.6754      400   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        8001.1   0.000792021       147.659      0.5991           1      526   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     488       8002.21   7.22552e-05       102.114   1.519e-07       0.001      675  LS failed, Hessian reset \n",
      "     499       8002.91   0.000721449       137.606           1           1      690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       8003.64     0.0047848       521.672           1           1      814   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     628       8004.26   5.71296e-05       153.514   1.864e-07       0.001      890  LS failed, Hessian reset \n",
      "     699       8004.62    0.00078023       134.695           1           1      976   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     753       8004.75   5.63457e-07        75.462           1           1     1045   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -19.4685\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       7975.31    0.00415855       247.015      0.7831      0.7831      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       7994.53      0.010249        344.02           1           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     223       7995.33   5.91718e-05       165.006   4.517e-07       0.001      316  LS failed, Hessian reset \n",
      "     299       7997.26   0.000813407       209.659       6.754      0.6754      400   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        8001.1   0.000792021       147.659      0.5991           1      526   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     488       8002.21   7.22552e-05       102.114   1.519e-07       0.001      675  LS failed, Hessian reset \n",
      "     499       8002.91   0.000721449       137.606           1           1      690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       8003.64     0.0047848       521.672           1           1      814   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     628       8004.26   5.71296e-05       153.514   1.864e-07       0.001      890  LS failed, Hessian reset \n",
      "     699       8004.62    0.00078023       134.695           1           1      976   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     753       8004.75   5.63457e-07        75.462           1           1     1045   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -19.4685\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       7975.31    0.00415855       247.015      0.7831      0.7831      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       7994.53      0.010249        344.02           1           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     223       7995.33   5.91718e-05       165.006   4.517e-07       0.001      316  LS failed, Hessian reset \n",
      "     299       7997.26   0.000813407       209.659       6.754      0.6754      400   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        8001.1   0.000792021       147.659      0.5991           1      526   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     488       8002.21   7.22552e-05       102.114   1.519e-07       0.001      675  LS failed, Hessian reset \n",
      "     499       8002.91   0.000721449       137.606           1           1      690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       8003.64     0.0047848       521.672           1           1      814   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     628       8004.26   5.71296e-05       153.514   1.864e-07       0.001      890  LS failed, Hessian reset \n",
      "     699       8004.62    0.00078023       134.695           1           1      976   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     753       8004.75   5.63457e-07        75.462           1           1     1045   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = -19.4685\n",
      "1.74 s ± 12.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      99       7975.31    0.00415855       247.015      0.7831      0.7831      127   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     199       7994.53      0.010249        344.02           1           1      243   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     223       7995.33   5.91718e-05       165.006   4.517e-07       0.001      316  LS failed, Hessian reset \n",
      "     299       7997.26   0.000813407       209.659       6.754      0.6754      400   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     399        8001.1   0.000792021       147.659      0.5991           1      526   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     488       8002.21   7.22552e-05       102.114   1.519e-07       0.001      675  LS failed, Hessian reset \n",
      "     499       8002.91   0.000721449       137.606           1           1      690   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     599       8003.64     0.0047848       521.672           1           1      814   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     628       8004.26   5.71296e-05       153.514   1.864e-07       0.001      890  LS failed, Hessian reset \n",
      "     699       8004.62    0.00078023       134.695           1           1      976   \n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "     753       8004.75   5.63457e-07        75.462           1           1     1045   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = 8004.07\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      66       8004.15   5.22013e-07       53.0641       0.214       0.214       94   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = 8004.07\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      66       8004.15   5.22013e-07       53.0641       0.214       0.214       94   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = 8004.07\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      66       8004.15   5.22013e-07       53.0641       0.214       0.214       94   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = 8004.07\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      66       8004.15   5.22013e-07       53.0641       0.214       0.214       94   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = 8004.07\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      66       8004.15   5.22013e-07       53.0641       0.214       0.214       94   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = 8004.07\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      66       8004.15   5.22013e-07       53.0641       0.214       0.214       94   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = 8004.07\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      66       8004.15   5.22013e-07       53.0641       0.214       0.214       94   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n",
      "Initial log joint probability = 8004.07\n",
      "210 ms ± 1.68 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "    Iter      log prob        ||dx||      ||grad||       alpha      alpha0  # evals  Notes \n",
      "      66       8004.15   5.22013e-07       53.0641       0.214       0.214       94   \n",
      "Optimization terminated normally: \n",
      "  Convergence detected: relative gradient magnitude is below tolerance\n"
     ]
    }
   ],
   "source": [
    "def stan_init(m):\n",
    "    \"\"\"Retrieve parameters from a trained model.\n",
    "    \n",
    "    Retrieve parameters from a trained model in the format\n",
    "    used to initialize a new Stan model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    m: A trained model of the Prophet class.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Dictionary containing retrieved parameters of m.\n",
    "    \n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    for pname in ['k', 'm', 'sigma_obs']:\n",
    "        res[pname] = m.params[pname][0][0]\n",
    "    for pname in ['delta', 'beta']:\n",
    "        res[pname] = m.params[pname][0]\n",
    "    return res\n",
    "\n",
    "df = pd.read_csv('../examples/example_wp_log_peyton_manning.csv')\n",
    "df1 = df.loc[df['ds'] < '2016-01-19', :]  # All data except the last day\n",
    "m1 = Prophet().fit(df1) # A model fit to all data except the last day\n",
    "\n",
    "\n",
    "%timeit m2 = Prophet().fit(df)  # Adding the last day, fitting from scratch\n",
    "%timeit m2 = Prophet().fit(df, init=stan_init(m1))  # Adding the last day, warm-starting from m1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the parameters from the previous model are passed in to the fitting for the next with the kwarg `init`. In this case, model fitting was about 5x faster when using warm starting. The speedup will generally depend on how much the optimal model parameters have changed with the addition of the new data.\n",
    "\n",
    "There are few caveats that should be kept in mind when considering warm-starting. First, warm-starting may work well for small updates to the data (like the addition of one day in the example above) but can be worse than fitting from scratch if there are large changes to the data (i.e., a lot of days have been added). This is because when a large amount of history is added, the location of the changepoints will be very different between the two models, and so the parameters from the previous model may actually produce a bad trend initialization. Second, as a detail, the number of changepoints need to be consistent from one model to the next or else an error will be raised because the changepoint prior parameter `delta` will be the wrong size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### External references\n",
    "These github repositories provide examples of building on top of Prophet in ways that may be of broad interest:\n",
    "* [forecastr](https://github.com/garethcull/forecastr): A web app that provides a UI for Prophet.\n",
    "* [NeuralProphet](https://github.com/ourownstory/neural_prophet): A Prophet-style model implemented in pytorch, to be more adaptable and extensible."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
